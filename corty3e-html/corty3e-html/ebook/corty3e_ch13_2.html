<!DOCTYPE html>
<!--[if lt IE 7 ]> <html lang="en" class="no-js ie6"> <![endif]-->
<!--[if IE 7 ]>    <html lang="en" class="no-js ie7"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en" class="no-js ie8"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en" class="no-js ie9"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html lang="en" class="no-js"> <!--<![endif]-->
<head>
    <title>corty3e_ch13</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
                    <link href="css/boilerplate.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/jquery-ui-custom.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/manuscript.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/digfir_ebook_fw.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/corty3e.css" media="screen" rel="stylesheet" type="text/css" >
<link href="css/corty3e_ch13.css" media="screen" rel="stylesheet" type="text/css" >    
    
    </head>
<body class="noUi">
<div id="manuscript" data-chapter-number="13">
    <div data-type="section" data-block_type="h1" id="corty3e-ch13-sec1-1" level="1" data-print_page="479">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec1-1"><span data-block_type="sec_num">13.1</span> <span data-block_type="sec_title">Introduction to the Pearson Correlation Coefficient</span>
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p16"><p>There are multiple statistical tests that measure relationships by calculating correlation coefficients. In subsequent chapters, we’ll cover the Spearman rank-order correlation coefficient and the chi-square test of independence. But, the focus of this chapter is the head of the relationship test household, the most commonly used relationship test, the Pearson correlation coefficient. Usually, it is referred to as the Pearson <em>r</em>, or simply <em>r</em>.</p></div>
<div data-block_type="page_start" id="corty3e_page_480"><p>480</p></div>
<div data-block_type="txt" id="corty3e-ch13-p17"><p>Here is what we’ll cover in the first part of the chapter as we introduce <em>r</em>:</p></div>
<ul data-block_type="bullet" id="corty3e-ch13-list-2">
<li><div data-block_type="bl-first" id="corty3e-ch13-p18"><p>Defining Pearson <em>r</em> and “relationship”</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p19"><p>Exploring what a relationship says about cause and effect</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p20"><p>Seeing how to visualize a relationship</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p21"><p>Learning the difference between weak and strong relationships</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p22"><p>Seeing how <em>z</em> scores define the Pearson <em>r</em></p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p23"><p>Learning how the Pearson <em>r</em> quantifies relationship strength</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p24"><p>Exploring the two directions a relationship can take</p></div>
</li>
<li><div data-block_type="bl-last" id="corty3e-ch13-p25"><p>Learning about conditions that affect Pearson <em>r</em></p></div>
</li>
</ul>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-1" level="2" data-print_page="480">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-1">Defining Pearson <em>r</em> and Relationship
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p26"><p>Measures of association are statistics that quantify the degree of relationship between two variables. If two variables are related, they are said to be <em>correlated.</em> This means that the variables vary together systematically, that a change in one variable is associated with a change in the other. For example, alcohol consumption and blood alcohol level vary together systematically—the more alcohol a person consumes, the higher the level of alcohol in his or her blood. Depending on sex and weight as shown in <strong><span data-type="link" data-href="#corty3e-ch13-fig-1">Table 13.1</span></strong>, the relationship between the number of drinks consumed and blood alcohol level is well established.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-1" data-block_type="table" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_table13_01.jpg" data-figure-id="corty3e-ch13-fig-1" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
</div>
<div data-block_type="txt" id="corty3e-ch13-p27"><p>The Pearson <em>r</em> is a specific measure of association. A <span data-type="termref" data-term="Pearson correlation coefficient">Pearson correlation coefficient</span> quantifies the degree of linear relationship between two interval and/or ratio variables. Because the Pearson <em>r</em> uses interval and/or ratio variables, distances between points can be measured, <em>z</em> scores calculated, and graphs made. The graphs, called scatterplots, can be examined for the degree to which the relationship between the two variables takes the form of a straight line because the Pearson <em>r</em> measures the degree of linear relationship. (We’ll discuss nonlinear relationships, and why Pearson <em>r</em> is not appropriate to use in those cases, later in this chapter.)</p></div>
<div data-block_type="page_start" id="corty3e_page_481"><p>481</p></div>
<div data-type="box" data-block_type="bx-1-h" id="corty3e-ch13-bx1-1"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="corty3e-ch13-bx1-1">A Common Question</h3>
<div data-block_type="bx1-que" id="corty3e-ch13-p28"><p><strong>Q</strong> If the Pearson <em>r</em> only measures association between two interval and/or ratio variables, what is used for ordinal and/or nominal variables?</p></div>
<div data-block_type="bx1-ans" id="corty3e-ch13-p29"><p><strong>A</strong> If one variable is ordinal and the other is an ordinal, interval, or ratio variable, then association can be measured with a test called the Spearman rank-order correlation coefficient, or Spearman <em>r</em> for short. Association between two nominal variables is measured with the chi-square test of independence. Both of these tests are covered in <span data-type="link" data-href="corty3e-ch15.xml">Chapter 15</span>.</p></div>
</div></div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-2" level="2" data-print_page="481">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-2">Correlation, Causation, and Association
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p30"><p>If two variables correlate, the relationship <em>may</em> be a cause-and-effect relationship, but it doesn’t have to be. Statisticians love to say, “Correlation is not causation.” That’s because correlation between two variables does not guarantee a cause-and-effect relationship between them. A correlation between two variables only guarantees there is an <em>association</em> between the two variables, not that one causes the other.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p31"><p>To understand this, look at <strong><span data-type="link" data-href="#corty3e-ch13-fig-2">Figure 13.1</span></strong>. This type of graph, called a scatterplot, displays the relationship between two variables. For a random sample of 24 states, this graph shows the association between the number of community hospitals in a state (on the <em>X</em>-axis) and the number of deaths per year in the state (on the <em>Y</em>-axis). Each point represents a state. For example, Delaware, the state at the bottom left of the graph, has 6 community hospitals and about 7,000 deaths per year; New York, the state at the top right, has 206 community hospitals and about 153,000 deaths.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-2" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_01.jpg" data-figure-id="corty3e-ch13-fig-2" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.2: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.1</span> Relationship at a State Level Between Number of Community Hospitals and Number of Deaths</strong> This scatterplot illustrates the relationship between the number of community hospitals per state and the number of deaths per year in that state. States with more hospitals have more deaths. </span>
</div>
<div data-type="asset_source">(Credit: Thanks to Jillian Mrozowski, who obtained these data.) </div>
</div>
<div data-block_type="page_start" id="corty3e_page_482"><p>482</p></div>
<div data-block_type="txt" id="corty3e-ch13-p32"><p>The scatterplot shows clear evidence of an association between the two variables. The two variables vary together systematically: states like Delaware, with few hospitals have few deaths, and states like New York, with a lot of hospitals, experience a lot of deaths.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p33"><p>The relationship can be read in either direction. So far, this relationship has been viewed as states with more hospitals have more deaths. But, the scatterplot can be viewed just as legitimately as showing that states with more deaths have more hospitals.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p34"><p>If two variables are correlated, it simply means that they vary together systematically. A cause-and-effect relationship may exist between them, but there does not have to be. The number of deaths in a state and the number of community hospitals are correlated, but it doesn’t seem plausible that there is a cause-and-effect relationship between them. If such a relationship did exist, then a state could reduce the number of people who die each year by closing down hospitals. That doesn’t seem to be a course of action likely to work.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p35"><p>The number of hospitals per state and the number of deaths vary together systematically, but they don’t cause each other. Their correlation most likely results because each is associated with a third variable, population. States with more people, like New York, have more of everything than states with fewer people, like Delaware. New York, with a population of almost 20 million, has more pencils, cars, barbers, and murders than Delaware, with under a million residents. New York also has more community hospitals and more deaths, simply because more people live there.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p36"><p>Correlation just means two variables systematically vary together. If the goal of science is to understand cause and effect, it may seem that drawing a conclusion that two variables are associated represents a second-place finish. Not so. Correlation does not <em>have to</em> mean causation, but it <em>may</em> mean causation. If there is a cause-and-effect relationship between two variables, then they are correlated. An association exists between how much alcohol a person consumes and what his or her blood alcohol level is because consuming alcohol causes the alcohol concentration in the blood to rise.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p37"><p>Correlation may not prove cause and effect, but it can suggest cause. For example, finding that children who watch more violent TV tend to exhibit more aggressive behaviors doesn’t prove that TV is the culprit, but it certainly raises such a question and leads to more research. Thus, correlations are not proof of cause and effect, but they often serve as a jumping off point for using experimental techniques to explore cause and effect.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p38"><p>Studies in which the variables in a relationship test are not manipulated by the researcher do not address cause and effect. In a relationship test, it is rare that the explanatory variable is an independent variable and the outcome variable is called a dependent variable. Most commonly, they are just called <em>X</em> and <em>Y</em> and that’s what we’ll do here. However, if the researcher believes there is an order to the relationship, then the explanatory variable is called the <em>predictor variable</em> and the outcome variable is called the <em>outcome variable.</em> The language is meant to be straightforward—the variable that comes first, that is thought of as leading to or influencing the other variable, is the <span data-type="termref" data-term="predictor variable">predictor variable</span>. The one that comes second, and is influenced by the first variable, is the <span data-type="termref" data-term="outcome variable">outcome variable</span>.</p></div>
<div data-block_type="page_start" id="corty3e_page_483"><p>483</p></div>
<div data-type="box" data-block_type="bx-1-h" id="corty3e-ch13-bx1-2"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="corty3e-ch13-bx1-2">A Common Question</h3>
<div data-block_type="bx1-que" id="corty3e-ch13-p39"><p><strong>Q</strong> Can a correlation give cause-and-effect information?</p></div>
<div data-block_type="bx1-ans" id="corty3e-ch13-p40"><p><strong>A</strong> There is a difference between correlation, referring to the statistical test, and a correlational study. In the latter, the explanatory variable is not controlled by the experimenter, so a cause-and-effect conclusion cannot be reached. But, it would be possible to design a study where the experimenter manipulates the explanatory variable and where the results would be analyzed with a Pearson <em>r</em>. In such a case, a correlation coefficient would give cause-and-effect information.</p></div>
</div></div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-3" level="2" data-print_page="483">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-3">Visualizing Relationships
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p41"><p>The degree to which two variables vary together determines whether the relationship is strong or weak. The strength of the relationship can be visualized in a scatterplot. <strong><span data-type="link" data-href="#corty3e-ch13-fig-3">Figure 13.2</span></strong> shows the relationship between randomly generated numbers. If <em>X</em> values are randomly selected and each <em>X</em> is paired with a randomly selected <em>Y,</em> then the two do not vary together systematically. <span data-type="link" data-href="#corty3e-ch13-fig-3">Figure 13.2</span> shows a rectangular scatterplot where there is <em>no</em> relationship, what is called a zero correlation, between two variables. Cases with low values on <em>X</em> could have low, medium, or high values on <em>Y.</em> And, the same is true for cases with medium or high values on <em>X.</em></p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-3" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_02.jpg" data-figure-id="corty3e-ch13-fig-3" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.3: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.2</span> Lack of Relationship Between Randomly Generated Values of <em>X</em> and Randomly Generated Values of <em>Y</em></strong> When the two variables don’t vary together systematically, there is no relationship between <em>X</em> and <em>Y.</em> This is one example of what no relationship looks like.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p42"><p>Though the rectangular scatterplot shows a zero correlation clearly, that is not how statisticians illustrate a zero correlation. Statisticians use a circular scatterplot to demonstrate no relationship between two variables. If both variables are normally distributed, which is one of the assumptions for the Pearson <em>r,</em> then the scatterplot has a circular shape when no relationship exists. <strong><span data-type="link" data-href="#corty3e-ch13-fig-4">Figure 13.3</span></strong> uses the traditional circular shape to illustrate the lack of relationship between two normally distributed variables.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-4" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_03.jpg" data-figure-id="corty3e-ch13-fig-4" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.4: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.3</span> Zero Correlation Between Two Normally Distributed Variables</strong> If there is no correlation between two normally distributed variables, the scatterplot looks more like a circle than a rectangle. This shows the hypothetical lack of a relationship between foot size and intelligence.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p43"><p>What does a scatterplot look like when there <em>is</em> a relationship between two variables and they vary systematically? <strong><span data-type="link" data-href="#corty3e-ch13-fig-5">Figure 13.4</span></strong> illustrates the relationship between the temperatures of objects measured in both degrees Fahrenheit and Celsius. This figure is an example of the strongest possible linear relationship between two variables, a <span data-type="termref" data-term="perfect relationship">perfect relationship</span><strong>.</strong> In a perfect relationship, all the data points fall along a straight line. <span data-type="link" data-href="#corty3e-ch13-fig-5">Figure 13.4</span> shows that knowing an object’s temperature in Fahrenheit tells one exactly what it is in Celsius.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-5" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_04.jpg" data-figure-id="corty3e-ch13-fig-5" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.5: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.4</span> A Perfect Linear Relationship</strong> Note that all data points fall on a straight line. The relationship between temperature as measured in degrees Fahrenheit and degrees Celsius is a perfect one.</span>
</div>
</div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-4" level="2" data-print_page="483">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-4">Strength of Relationships
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p44"><p>A strong relationship is one in which cases’ scores on variable <em>X</em> are closely allied with their scores on variable <em>Y.</em> When looking at a scatterplot, strength is shown by how well the points fall along a straight line. The more the points fall in a straight line, the stronger the association. <strong><span data-type="link" data-href="#corty3e-ch13-fig-6">Figure 13.5</span></strong> gives four scatterplots. As the points form less of a line and more of a blob, as they move from a line to an oval or a circle, the relationship grows weaker.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-6" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_05.jpg" data-figure-id="corty3e-ch13-fig-6" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.6: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.5</span> Visualizing the Strength of Relationships</strong> These four scatterplots differ in the degree to which the points form a straight line or are spread out to form an oval. As the amount of spread increases—as the points fall less along a line—the relationship becomes weaker.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p45"><p>Two situations exist in which the points in a scatterplot form a straight line, but the relationship is not a perfect one. These occur when the line is horizontal or vertical. When the line is horizontal, for example, every value of <em>X</em> is paired with the same value of <em>Y.</em> There is no variability in <em>Y.</em> With a vertical line, the opposite is true and there is no variability in <em>X.</em> The Pearson <em>r</em> formula needs both variables to have variability, and if either variable has none, Pearson <em>r</em> can’t be calculated. In these situations, <em>r</em> is said to be undefined.</p></div>
<div data-block_type="page_start" id="corty3e_page_484"><p>484</p></div>
<div data-block_type="page_start" id="corty3e_page_485"><p>485</p></div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-5" level="2" data-print_page="485">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-5">Correlations Defined by <em>z</em> Scores
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p46"><p>A scatterplot can also be drawn using <em>z</em> scores, not raw scores. <em>z</em> scores, also called standard scores, were introduced in <span data-type="link" data-href="corty3e-ch04.xml">Chapter 4</span>. They are a transformation of raw scores into scores that reveal how far away from the mean the scores are in standard deviation units. <em>z</em> scores can be positive or negative, which means they fall above the mean or below the mean.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p47"><p><strong><span data-type="link" data-href="#corty3e-ch13-fig-7">Figure 13.6</span></strong> offers scatterplots for the community hospital/number of deaths data. The panel on the left in 13.6, like <span data-type="link" data-href="#corty3e-ch13-fig-2">Figure 13.1</span>, illustrates the relationship with raw scores, and the panel on the right shows what the scatterplot looks like when the same variables are transformed into <em>z</em> scores. Note that transforming from raw scores to <em>z</em> scores doesn’t change the relationship. The pattern of the dots, the shape, is exactly the same, whether raw scores or <em>z</em> scores are being plotted.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-7" data-block_type="figure" data-layout-align="center" data-layout-width="xlarge" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_06.jpg" data-figure-id="corty3e-ch13-fig-7" data-layout-width="xlarge" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.7: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.6</span> Number of Community Hospitals and Number of Deaths: Raw Scores and</strong> <em>z</em> <strong>Scores</strong> When raw scores are transformed into <em>z</em> scores, the scales on the axes change, but not the shape of the scatterplot. The dots form the same pattern in both of these scatterplots.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p48"><p><strong><span data-type="link" data-href="#corty3e-ch13-fig-8">Figure 13.7</span></strong> shows the scatterplot for the relationship between temperature as measured in Fahrenheit and Celsius both with raw scores (the panel on the left) and with <em>z</em> scores (the panel on the right). These <em>z</em> scores give a new perspective on what a correlation means. Look at the dot on the upper right, which is for boiling water. In the panel on the left, the <em>X</em> value for this point is 212° (Fahrenheit) and the <em>Y</em> value is 100° (Celsius). To a person who doesn’t know much about Fahrenheit and Celsius, those scores don’t sound similar as they are 112 points apart. In the panel on the right, the <em>z</em> scores for this point are <em>z<sub>X</sub></em> = 1.63 and <em>z<sub>Y</sub></em> = 1.63. That is, the boiling point of water is exactly as far above the mean when measured in Fahrenheit as when it is measured in Celsius. That’s what a perfect correlation means.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-8" data-block_type="figure" data-layout-align="center" data-layout-width="xlarge" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_07.jpg" data-figure-id="corty3e-ch13-fig-8" data-layout-width="xlarge" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.8: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.7</span> A Perfect Relationship: Raw Scores vs.</strong> <em>z</em> <strong>Scores</strong> With a perfect relationship, a case’s <em>z</em> score on the <em>X</em> variable has exactly the same value as it does on the <em>Y</em> variable. In the panel on the left, the data point for boiling water occurs at the intersection of 212°F and 100°C. In the panel on the right, the data point is at the intersection of <em>z</em> scores of 1.63 on both axes.</span>
</div>
</div>
<div data-block_type="page_start" id="corty3e_page_486"><p>486</p></div>
<div data-block_type="page_start" id="corty3e_page_487"><p>487</p></div>
<div data-block_type="txt" id="corty3e-ch13-p49"><p>As correlations get weaker, the similarity between <em>z<sub>X</sub></em> and <em>z<sub>Y</sub></em> lessens. The community hospital/number of deaths data show a strong correlation, but not a perfect one. The point on the upper right is New York with 206 hospitals and 153,000 deaths. Converted, those are <em>z</em> scores of 2.2 and 2.8. The two <em>z</em> scores are not the same, but they are in the same ballpark, both far above the mean. As correlations grow weaker and weaker, the similarity between the two <em>z</em> scores for each data point becomes less and less.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p50"><p>In fact, the similarity–dissimilarity of the pairs of <em>z</em> scores is one way of calculating what a Pearson correlation coefficient is. This formula, called the definitional formula, calculates a Pearson <em>r</em> as the average of multiplied-together pairs of <em>z</em> scores. Each case’s raw score on <em>X</em> is transformed into a <em>z</em> score and its raw score on <em>Y</em> is transformed into a <em>z</em> score. The two <em>z</em> scores for each case are multiplied together and the mean of these products is calculated. The mean of all such multiplied-together scores is a Pearson correlation coefficient. Thus, the stronger the correlation, the more similar—on average—the <em>z</em> scores are.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p51"><p>Here is a quick example to illustrate the benefit of the <em>z</em> score method. Many years ago, the United States Postal Service ran an ad showing that they, compared to the United Parcel Service and FedEx, had the largest fleet of trucks. The totals were, respectively, 200,000, 130,000, and 35,000. The USPS also had the lowest price for overnight delivery among the three shippers—respectively, $3, $6, and $12. As the scatterplot in <strong><span data-type="link" data-href="#corty3e-ch13-fig-9">Figure 13.8</span></strong> makes clear, this is a strong relationship: more trucks is associated with lower cost.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-9" data-block_type="figure" data-layout-align="center" data-layout-width="medium" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_08.jpg" data-figure-id="corty3e-ch13-fig-9" data-layout-width="medium" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.9: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.8</span> Relationship Between Fleet Size and Cost of Overnight Letter</strong> This scatterplot shows a strong relationship between how many trucks a delivery service has and the amount it charges for overnight delivery. </span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p52"><p><strong><span data-type="link" data-href="#corty3e-ch13-fig-10">Table 13.2</span></strong> shows the data, both as raw scores and transformed into <em>z</em> scores. Note how much clearer the relationship between the two variables is when expressed in <em>z</em> scores. The number of trucks the United States Postal Service has is as far above the mean, <em>z</em> = 0.95, as its price is below the mean, <em>z</em> = –0.87. This, the strength of the relationship between variable X expressed as a <em>z</em> score and variable Y expressed as a <em>z</em> score, is what the Pearson <em>r</em> expresses.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-10" data-block_type="table" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_table13_02.jpg" data-figure-id="corty3e-ch13-fig-10" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
</div>
<div data-block_type="page_start" id="corty3e_page_488"><p>488</p></div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-6" level="2" data-print_page="488">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-6">Quantifying Relationships
</span></h2>

<div data-type="box" data-block_type="mn1" id="corty3e-ch13-exp1-1"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="corty3e-ch13-exp1-1"></h3>
<div data-block_type="mn-ext-ni" id="corty3e-ch13-p53"><p><em>A correlation coefficient is a number that summarizes the strength of the relationship between two variables.</em></p></div>
</div></div>
<div data-block_type="txt-ni" id="corty3e-ch13-p54"><p>Scatterplots are great for visualizing relationships, but their interpretation is subjective. For example, can the owner of a baseball team buy his or her way to the World Series? <strong><span data-type="link" data-href="#corty3e-ch13-fig-11">Figure 13.9</span></strong> is a scatterplot showing the relationship between the payrolls of Major League Baseball teams and their winning percentages. How strong is the association? Just by looking at the graph, it is difficult to tell how strong the relationship between these two variables is. Deciding how strong a relationship is on the basis of a scatterplot is subjective and different people can have different—and valid—opinions. One person might interpret the points on <span data-type="link" data-href="#corty3e-ch13-fig-11">Figure 13.9</span> as roughly linear and conclude that the payroll is strongly related to a team’s performance. Another may see the circular clump of scores in the middle of the graph and conclude that there doesn’t appear to be much of a relationship.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-11" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_09.jpg" data-figure-id="corty3e-ch13-fig-11" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.11: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.9</span> Relationship Between Team Payroll and Team Success in Major League Baseball</strong> This scatterplot shows the relationship between the payrolls of Major League Baseball teams and their winning percentages.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p55"><p>The Pearson <em>r</em> gets around this problem of how specific the prediction is by calculating a statistic called a <em>correlation coefficient.</em> A <span data-type="termref" data-term="correlation coefficient">correlation coefficient</span> is a number that summarizes the strength of the linear relationship between two variables. For the Pearson <em>r,</em> the correlation coefficient is abbreviated as <em>r</em> (think of <em>r</em> as being short for “relationship”). For a Pearson correlation, <em>r</em> is a value that ranges from –1.00 to +1.00. An <em>r</em> value of zero is less than a weak relationship; it means that there is <em>no</em> relationship between the two variables. <span data-type="link" data-href="#corty3e-ch13-fig-3">Figure 13.2</span>, where the dots form a rectangle, and <span data-type="link" data-href="#corty3e-ch13-fig-4">Figure 13.3</span>, where the dots form a circle, have Pearson <em>r</em> values of zero.</p></div>
<div data-block_type="page_start" id="corty3e_page_489"><p>489</p></div>
<div data-block_type="txt" id="corty3e-ch13-p56"><p>As the <em>r</em> value moves further away from zero, in either a negative or positive direction, it represents a stronger relationship between <em>X</em> and <em>Y.</em> For example, an <em>r</em> of –.60 represents a stronger relationship than an <em>r</em> of .30. Pearson <em>r</em> values of –1.00 and 1.00, though they differ in sign, both represent perfect relationships.</p></div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-7" level="2" data-print_page="489">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-7">Direction of the Relationship
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p57"><p>Though Pearson <em>r</em> values of –1.00 and 1.00 both represent perfect relationships, the two indicate different types of relationships because their signs differ. The sign of a Pearson <em>r,</em> either positive or negative, gives information about the <em>direction</em> of the relationship. There are two options for direction: positive or negative.</p></div>
<ul data-block_type="bullet" id="corty3e-ch13-list-3">
<li><div data-block_type="bl-first" id="corty3e-ch13-p58"><p><span data-type="termref" data-term="Positive relationships">Positive relationships</span><strong>.</strong> Positive <em>r</em>’s are found for what are called direct relationships. <span data-type="termref" data-term="Direct relationships">Direct relationships</span> have scatterplots where the points tend to fall along a line moving from the bottom on the left, up and to the right. This means that cases with low scores on the <em>X</em> variable tend to have low scores on the <em>Y</em> variable and those with high scores on the <em>X</em> variable will tend to have high scores on the <em>Y</em> variable. For example, within a community there’s a positive relationship between the size of a house and how much it costs. In general, smaller houses cost less money and bigger houses cost more money. This positive relationship is illustrated in <strong><span data-type="link" data-href="#corty3e-ch13-fig-12">Figure 13.10</span></strong>.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-12" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_10.jpg" data-figure-id="corty3e-ch13-fig-12" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.12: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.10</span> Positive Relationship Between the Size of a House and Its Cost</strong> In a positive relationship, the data points in a scatterplot fall along a diagonal line that moves up and to the right. In this scatterplot, as the size of the house increases, the price generally does as well.</span>
</div>
</div>
<div data-block_type="page_start" id="corty3e_page_490"><p>490</p></div>
</li>
<li><div data-block_type="bl-mid" id="corty3e-ch13-p59"><p><span data-type="termref" data-term="Negative relationships">Negative relationships</span><strong>.</strong> Negative <em>r</em>’s are also called inverse relationships. <span data-type="termref" data-term="Inverse relationships">Inverse relationships</span> have scatterplots where the points fall along a line moving from the top left, down and to the right. This means that cases with low scores on <em>X</em> tend to have high scores on <em>Y</em> and cases with high scores on the <em>X</em> variable will tend to have low scores on the <em>Y</em> variable. For example, <strong><span data-type="link" data-href="#corty3e-ch13-fig-13">Figure 13.11</span></strong> shows a relationship between a car’s horsepower and its fuel economy. The relationship is a negative one—in general, lower horsepower means better fuel economy and higher horsepower means worse fuel economy.</p></div>
</li>
</ul>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-13" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_11.jpg" data-figure-id="corty3e-ch13-fig-13" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.13: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.11</span> Negative Relationship Between Horsepower and Fuel Economy</strong> In a negative relationship, points form a line moving downward and to the right. This means that as one variable increases, the other decreases. Here, as the horsepower of cars goes up, miles per gallon go down. </span>
</div>
<div data-type="asset_source">(Credit: Thanks to Griffon Olon who collected these data.)</div>
</div>
</div>
    <div data-type="section" data-block_type="h2" id="corty3e-ch13-sec2-8" level="2" data-print_page="490">
<h2 class="section-title"><span data-type="title" data-title-for="corty3e-ch13-sec2-8">Conditions Affecting Pearson <em>r</em>
</span></h2>

<div data-block_type="txt-ni" id="corty3e-ch13-p60"><p>There are three conditions that affect a Pearson <em>r:</em> (1) nonlinearity, (2) outliers, and (3) restriction of range.</p></div>
<div data-block_type="h3" id="corty-ch13-chead-1"><p>Nonlinearity</p></div>
<div data-type="box" data-block_type="mn1" id="corty3e-ch13-exp1-2"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="corty3e-ch13-exp1-2"></h3>
<div data-block_type="mn-ext-ni" id="corty3e-ch13-p61"><p><em>The Pearson r only measures how much linear relationship exists between two variables.</em></p></div>
</div></div>
<div data-block_type="txt-ni" id="corty3e-ch13-p62"><p>The Pearson <em>r</em> is used to measure the degree of <em>linear</em> relationship between two variables. A linear relationship exists when the points in the scatterplot for the relationship between <em>X</em> and <em>Y</em> fall along a <em>straight</em> line. <strong><span data-type="link" data-href="#corty3e-ch13-fig-14">Figure 13.12</span></strong> illustrates a nonlinear association, what is called the Yerkes-Dodson law. The Yerkes-Dodson law states that arousal affects performance in an orderly way—low arousal leads to poor performance, moderate arousal leads to optimal performance, and high arousal impairs performance. This scatterplot shows a relationship between <em>X</em> and <em>Y,</em> but the points in the scatterplot don’t fall on a straight line. Using a Pearson correlation to quantify this relationship would provide a value close to zero, meaning there is little <em>linear</em> relationship between the two variables. The Pearson <em>r</em> only measures how much <em>linear</em> relationship exists between two variables. If the relationship appears nonlinear, do not use a Pearson <em>r</em> to measure it.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-14" data-block_type="figure" data-layout-align="center" data-layout-width="large" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_12.jpg" data-figure-id="corty3e-ch13-fig-14" data-layout-width="large" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.14: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.12</span> Example of a Curvilinear Relationship</strong> There is a relationship between <em>X</em> and <em>Y</em> in this scatterplot, but it is curvilinear, not linear. Because the relationship is not a straight-line relationship, the Pearson <em>r</em> would be near zero. An <em>r</em> of zero doesn’t mean there is no relationship. It just means that no linear relationship exists.</span>
</div>
</div>
<div data-block_type="page_start" id="corty3e_page_491"><p>491</p></div>
<div data-block_type="h3" id="corty-ch13-chead-2"><p>Outliers</p></div>
<div data-block_type="txt-ni" id="corty3e-ch13-p63"><p>Outliers are cases with extreme values, values that fall far away from the values that other cases have. One outlier in a data set can dramatically change the value of a correlation. The left panel in <strong><span data-type="link" data-href="#corty3e-ch13-fig-15">Figure 13.13</span></strong> shows a scatterplot for a small data set. The points form a rough circle and the correlation between <em>X</em> and <em>Y</em> is zero.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-15" data-block_type="figure" data-layout-align="center" data-layout-width="xlarge" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_13.jpg" data-figure-id="corty3e-ch13-fig-15" data-layout-width="xlarge" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.15: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.13</span> Effect of an Outlier on a Pearson Correlation</strong> The correlation in the left scatterplot is zero. In the right scatterplot, the correlation is .63 thanks to the addition of one case. The additional case is an outlier, with extreme values on <em>X</em> and <em>Y.</em></span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p64"><p>The right panel in <span data-type="link" data-href="#corty3e-ch13-fig-15">Figure 13.13</span> adds one data point, an outlier with extreme values on both <em>X</em> and <em>Y.</em> This data point has an <em>X</em> value and a <em>Y</em> value that are dramatically higher than any other case. As a result of adding this one case, the correlation between <em>X</em> and <em>Y</em> changes from <em>r</em> = .00 to <em>r</em> = .63.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p65"><p>Outliers inflate the strength of a relationship between two variables. Because outliers may exist, it is always a good idea to create and inspect a scatterplot before calculating a correlation coefficient.</p></div>
<div data-block_type="page_start" id="corty3e_page_492"><p>492</p></div>
<div data-block_type="h3" id="corty-ch13-chead-3"><p>Restriction of Range</p></div>
<div data-block_type="txt-ni" id="corty3e-ch13-p66"><p>While outliers inflate the value of a correlation, restriction of range tends to deflate the value of a correlation. This means that a restricted range could lead a researcher to conclude that there is less of a relationship between two variables than actually exists.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p67"><p>What is restriction of range? Let’s consider an unrestricted range first. Look at the left panel of <strong><span data-type="link" data-href="#corty3e-ch13-fig-16">Figure 13.14</span></strong>, a scatterplot showing the hypothetical relationship between IQ and GPA in a sample of high school students. There is a full (unrestricted) range of IQ scores, ranging from 70 to 130. And, there is a full (unrestricted) range of GPA, from 0 to 4. Judging by the noncircular shape of the scatterplot, the correlation between these two variables is strong.</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-16" data-block_type="figure" data-layout-align="center" data-layout-width="xlarge" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_14.jpg" data-figure-id="corty3e-ch13-fig-16" data-layout-width="xlarge" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
<div data-type="figure_text">
<span data-type="number">Figure 13.16: </span><span data-type="caption"><strong><span data-block_type="fig_num">Figure 13.14</span> Effect of Restriction of Range on Correlation Coefficients</strong> The left scatterplot shows the strong relationship between IQ and GPA for a large sample of high school students. The right scatterplot depicts the relationship when the analysis is restricted to people with IQs of 115 or higher <em>and</em> GPAs of 3 or higher. Note how the shape of this sample with restricted ranges on both variables is more circular, which means the relationship between IQ and GPA will be much weaker. A restricted range deflates the value of a correlation.</span>
</div>
</div>
<div data-block_type="txt" id="corty3e-ch13-p68"><p>Suppose a researcher decided to restrict her examination of the relationship between IQ and GPA to students likely to be accepted at Ivy League colleges. Thus, she restricted her sample to students with IQs above 115 <em>and</em> GPAs above 3.00. The two lines in the top panel are the cut-off values for her sample and the few cases that fall in the upper right quadrant are the new sample.</p></div>
<div data-block_type="txt" id="corty3e-ch13-p69"><p>This subsample has a restricted range on <em>both</em> the <em>X</em> variable and the <em>Y</em> variable. The new sample is shown in a scatterplot all by itself, in the right panel of <span data-type="link" data-href="#corty3e-ch13-fig-16">Figure 13.14</span>. What is the shape of this scatterplot? The points fall roughly in a circle, meaning that little correlation will be found between <em>X</em> and <em>Y.</em> Restricting the range of one or both variables in a correlation deflates its value.</p></div>
<div data-block_type="page_start" id="corty3e_page_493"><p>493</p></div>
<div data-type="box" data-block_type="sr-h" id="corty3e-ch13-bx2-1"><div data-type="box_inner">
<h3 data-type="title" data-for_type="box" data-title-for="corty3e-ch13-bx2-1">Practice Problems 13.1</h3>
<div data-block_type="sr-h1" id="corty3e-ch13-p70"><p><strong>Apply Your Knowledge</strong></p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p71"><p><span data-block_type="question_num">13.01</span> Make a scatterplot for these data:</p></div>
<div data-type="table" data-block_type="un_table" id="corty3e-ch13-table1" data-layout-align="center" data-layout-width="medium" data-layout-border="true" data-mmsrc="" data-attr=""><table><tbody>
<tr>
<td><span data-block_type="tbn-colhd"><strong><em>X</em></strong></span></td>
<td><span data-block_type="tbn-colhd"><strong><em>Y</em></strong></span></td>
<td><span data-block_type="tbn-colhd"><strong><em>X</em></strong></span></td>
<td><span data-block_type="tbn-colhd"><strong><em>Y</em></strong></span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">100</span></td>
<td><span data-block_type="tbn-txt">110</span></td>
<td><span data-block_type="tbn-txt">80</span></td>
<td><span data-block_type="tbn-txt">95</span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">90</span></td>
<td><span data-block_type="tbn-txt">85</span></td>
<td><span data-block_type="tbn-txt">100</span></td>
<td><span data-block_type="tbn-txt">95</span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">85</span></td>
<td><span data-block_type="tbn-txt">95</span></td>
<td><span data-block_type="tbn-txt">110</span></td>
<td><span data-block_type="tbn-txt">115</span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">90</span></td>
<td><span data-block_type="tbn-txt">95</span></td>
<td><span data-block_type="tbn-txt">85</span></td>
<td><span data-block_type="tbn-txt">80</span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">80</span></td>
<td><span data-block_type="tbn-txt">85</span></td>
<td><span data-block_type="tbn-txt">90</span></td>
<td><span data-block_type="tbn-txt">105</span></td>
</tr>
<tr>
<td><span data-block_type="tbn-txt">110</span></td>
<td><span data-block_type="tbn-txt">125</span></td>
<td></td>
<td></td>
</tr>
</tbody></table></div>
<div data-block_type="sr-que-txt-ni" id="corty3e-ch13-p72"><p><strong><em>Use the nine scatterplots below to answer Problems 13.02–13.07.</em></strong></p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p73"><p><span data-block_type="question_num">13.02</span> Which figure or figures have a linear relationship?</p></div>
<div data-type="figure" data-figure-id="corty3e-ch13-fig-17" data-block_type="un_figure" data-layout-align="center" data-layout-width="xlarge" data-layout-border="true">

<img id="" src="asset/ch13/corty3e_fig13_un01.jpg" data-figure-id="corty3e-ch13-fig-17" data-layout-width="xlarge" data-mmtype="image" data-mmsrc="" data-attr="" alt="image">
</div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p74"><p><span data-block_type="question_num">13.03</span> Which figure or figures represent no relationship?</p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p75"><p><span data-block_type="question_num">13.04</span> Which figure or figures have a weak linear relationship?</p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p76"><p><span data-block_type="question_num">13.05</span> Which figure or figures have a strong, but not perfect, linear relationship?</p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p77"><p><span data-block_type="question_num">13.06</span> Which figure or figures have a perfect linear relationship?</p></div>
<div data-block_type="sr-que-nl" id="corty3e-ch13-p78"><p><span data-block_type="question_num">13.07</span> Which figure or figures have a negative linear relationship?</p></div>
</div></div>
</div>
<!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --><!-- #x-digfir-subsection-insertion-point --></div><!-- /#manuscript -->
<br class="clear" />
<!-- end of material in original view -->

	<!--[if IE]><script type="text/javascript" src="js/excanvas.compiled.js"></script><![endif]-->
    
<script type="text/javascript" src="js/utilities.js"></script>
<script type="text/javascript" src="js/query_types.js"></script>
<script type="text/javascript" src="js/player.js"></script>
<script type="text/javascript" src="js/jquery.js"></script>
<script type="text/javascript" src="js/jquery-ui-1.8.16.custom.min.js"></script>
<script type="text/javascript" src="js/jquery_extensions.js"></script>
<script type="text/javascript" src="js/swfobject.js"></script>
<script type="text/javascript" src="http://admin.brightcove.com/js/BrightcoveExperiences.js"></script>
<script type="text/javascript" src="js/digfir_ebook_fw.js"></script>
<script type="text/javascript" src="js/corty3e.js"></script>
<script type="text/javascript" src="js/corty3e_ch13.js"></script>
<script type="text/javascript">
    //<!--
    
$(window).ready(function () {
	player.initialize('56d62d76757a2ebf47000007');
});
    //-->
</script>
</body>
</html>

